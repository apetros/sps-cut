@article{2024JKaragiannopoulos,
 abstract = {While moving towards a low-carbon, sustainable electricity system, distribution networks are expected to host a large share of distributed generators, such as photovoltaic units and wind turbines. These inverter-based resources are intermittent, but also controllable, and are expected to amplify the role of distribution networks together with other distributed energy resources, such as storage systems and controllable loads. The available control methods for these resources are typically categorized based on the available communication network into centralized, distributed, and decentralized or local. Standard local schemes are typically inefficient, whereas centralized approaches show implementation and cost concerns. This paper focuses on optimized decentralized control of distributed generators via supervised and reinforcement learning. We present existing state-of-the-art decentralized control schemes based on supervised learning, propose a new reinforcement learning scheme based on deep deterministic policy gradient, and compare the behavior of both decentralized and centralized methods in terms of computational effort, scalability, privacy awareness, ability to consider constraints, and overall optimality. We evaluate the performance of the examined schemes on a benchmark European low voltage test system. The results show that both supervised learning and reinforcement learning schemes effectively mitigate the operational issues faced by the distribution network.},
 author = {S. Karagiannopoulos and P. Aristidou and G. Hug and A. Botterud},
 doi = {10.1016/j.egyai.2024.100342},
 issn = {2666-5468},
 journal = {Energy and AI},
 keywords = {Supervised learning, Reinforcement learning, Deep deterministic policy gradient, Decentralized control, Active distribution systems},
 pages = {100342},
 projects = {machine-learning},
 title = {Decentralized control in active distribution grids via supervised and reinforcement learning},
 year = {2024}
}
